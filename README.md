<!-- author: Hermann Schranzhofer

email: hermann.schranzhofer@tugraz.at

version: 0.0.1

language: en

comment: This is a short course on the topic Research Data Management. It was created during the project FAIR Data Austria.

link: https://cdn.jsdelivr.net/chartist.js/latest/chartist.min.css

script: https://cdn.jsdelivr.net/chartist.js/latest/chartist.min.js

translation: Deutsch translations/German.md

\-->



# Open Educational Resources for Research Data Management



**Description:** The collection of open educational resources (OER) on the following pages was created by the Training Task Force in 2021 as part of the FAIR Data Austria project (BMBWF, 2020-2022). The collection consists of selected OER enhanced by further information and interactive elements to provide an introduction to the following nine topics. The pages or the individual elements can be reused to create informational and training materials on research data management.

**Authors:** Christiane Stork, Elena Fürst, Heike Thöricht, Hermann Schranzhofer, Nikos Gänsdorfer, Tereza Kalová, Therese Macher. The authors were supported by interns at the Vienna University Library in August 2021: Christine Stridde, Rebecca Ringbauer, Sonja Schillings, Tamara Köstenbach.

**License:** [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/) unless otherwise stated

**Cite the collection as:** FAIR Data Austria (2021). Open Educational Resources Research Data Management. Link to website (https://fair-office.at/index.php/lernen-sie-mehr/?lang=en).

[Learn more about FAIR](https://fair-office.at/index.php/information-for-researchers/learn-more-about-fair/?lang=en)



## File Formats



The file format is created by saving a file and contains information about the structure of data contained in a file, its purpose and affiliation. Application software can use the information available in the file format to interpret the data and make the contents available. The format of a file is added to the actual name with an appropriate extension. This consists of a point and two to four letters.

With so-called proprietary formats, the files can only be opened, edited and saved with the associated application, auxiliary or system programs (e.g. .doc/.docx, .xls/.xlsx). Open formats (e.g. .html, .jpg, .mp3, .gif), on the other hand, make it possible to open and edit the file with software from different manufacturers.

File formats can be actively changed by conversion when saving, but data loss can occur. In the scientific field, particular attention should be paid to compatibility, suitability for long-term archiving and lossless conversion to alternative formats.

!?[youtube](https://www.youtube.com/watch?v=kxxlQnc8u1I)

**Duration:** 5:12 min

**Content:** This short knowledge clip explains what file formats are, why they are important for research data management and what you should pay attention to.

**Licence:** [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.en)

**Transcript:**<!-- style="color: black; font-size: 20px;" -->

What is the importance of file formats in research data management?

A **file format** is a way of encoding information within a computer file. When a programme or an application wants to use a file, it needs to recognise the file format so that it can access the content within a file. One of the most common ways to recognise a file format is to look at the **file name extension**. Usually this is represented by three or four characters at the end of the file name after a full stop.

When you start planning your project, it is important to consider the file formats that you will use throughout your research. Sometimes the **choice of a format is influenced by norms** within your research discipline. For instance, by commonly used **software programmes** or file formats that you and your colleagues have used in the past. Or, the choice might also depend on the type of **hardware** or **instrument** you will use. In other situations, choosing a specific format might limit the possibility to collaborate with other scientist who don’t have access to the same software tools.

And last but not least, **certain file formats are less future proofed** than others. We often refer to this problem as **file format obsolescence**. And there are several reasons for this to happen. For example, sometimes older versions of a file format are no longer supported by **newer versions of the software**. Or, the software supporting the format is no longer available or cannot be used in newer operating systems. So, choosing the appropriate file format has implications doing your research project, but also for the long-term **usability of your data**.

All file formats are vulnerable to **obsolescence** to a certain degree. However, the sustainability of a file format can increase when you use what we call **open and standard formats**. Remember that a file format describes the way in which information is stored and organised within a computer file. If this description, known as **file format specification**, is available for anyone to see and free of charge, then we talk about **open file formats**. When a specification is not publicly available or there are limitations on how it can be reused, we talk about **closed formats**.

Let’s have a closer look. **Closed** formats, often called **proprietary formats**, are usually developed for commercial software applications. These files might only be readable with the same software used to create them for which licences is needed. Files produced with one version of the software might not be compatible with older or newer versions. Because the use of closed file formats depends on a specific software package or even a specific version of a software, they are **more vulnerable to obsolescence**. In other words, closed formats are less sustainable.

**Open file formats** can be both, proprietary and non-proprietary. Sometimes they are developed and maintained by a commercial company. But most often they are released by a standardisation body or a community without commercial interest. In any case, the file format specifications are open, which means that anyone can potentially develop software packages or applications that can use these formats, maximising the **interoperability and reuse** of information they contain. Besides, **compatibility with older versions** of the format is a priority. Making these types of formats **less subject to obsolescence issues**. So, in general open and non-proprietary formats are more sustainable when it comes to preserving data.

But sometimes we don’t have a choice but to use closed formats. In such cases it is good practice to also create a **copy of your files in an open format** to increase the chances of your data being accessible in the long term.

Actually, **file format conversion** might be needed at any moment of your research. For example, to use the data with a different software package or to share it with others. However, you should realise that converting files from one format to another might result in a **loss of content, metadata or quality**.

Before you **migrate files** to another format, it is important to be aware the **risks** and to test what can go wrong. It is also good practice to **keep the original files**, so you can always return to them and repair any errors or changes in your data if something goes wrong with your file conversion.

When choosing a file format, it might also be important to check what kind of **compression** is used. Compression is the process of encoding information using fewer bits than the original representation.

There are two types of compression. **Lossless compression** allows the original data to be perfectly reconstructed from the compressed data. When a file is compressed using this method, uncompressing it again results in a file that is identical to the original file.

But there are also **lossy types of compression** where some of the content is lost. Before performing a lossy compression, it is advisable to do some research to understand what compression parameters should be used. The objective should be to retain the critical information needed to make your files **reusable**.

As you can see, there are a few things to consider when it comes to file formats. To get started you can access a list of recommended formats via our website. Take a look!

**Quiz**<!-- style="color: black; font-size: 20px;" -->

What criteria should be considered when choosing a format?

    [( )] Formats are not of importance at all
    [(X)] Compatibility, suitability for long-term archiving and lossless conversion
    [( )] Proprietary data format and compressibility


Which file formats should be used?


    [( )] Files or formats should be encrypted, compressed, proprietary or patented
    [(X)] Open, documented standards should be preferred
    [( )] The file format does not matter, as software companies ensure compatibility anyway


What is the best way to ensure that digital data is accessible for a long time?


    [( )] The use and storage of proprietary data formats
    [( )] The use and storage of hardware-specific data formats
    [(X)] The use and storage of open data formats


**Further information**<!-- style="color: black; font-size: 20px;" -->

You can find further information including [descriptions of various file formats](https://www.loc.gov/preservation/digital/formats/fdd/descriptions.shtml) on the Library of Congress website.

You can download [data management best practices evaluation checklist](https://www.library.ucsb.edu/research-data-services/resources) from the UCSB Library for some helpful tips on file formats and organization.

**Citation**<!-- style="color: black; font-size: 20px;" -->

FAIR Data Austria (2021). “File formats “. In: Research Data Management Open Educational Resources Collection. (https://fair-office.at/index.php/fileformates/?lang=en).

License: [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/) unless otherwise stated.



## Data Management Plan (DMP)



Creating a Data Management Plan (DMP) for any research project is considered good scientific practice and increasingly mandated by research stakeholders. (Early) Planning for [Research Data Management (RDM)](#Research-Data-Management-%28RDM%29) can save a lot of time, money and problems in the long run and will therefore increase scientific integrity and transparency. **The content of a DMP covers core topics such as data description, documentation, metadata & standards, data storage & security, sharing & reuse, legal & ethical issues as well as responsibilities & costs related to research data management.**

The time for submission of the DMP depends on the individual requirements of institutions or funders. Generally, a DMP should be seen as a **living document** that starts as light version and grows gradually until submission of the full or final DMP version at the end of the project. Institutions or funders may provide special DMP templates or recommendations for DMP tools such as DMPonline or RDMO for the creation of a DMP.

!?[youtube](https://youtu.be/GRNsLTQGjCo)

**Duration:** 5:23 min

**Content:** In this knowledge clip we have a look at Data Management Plans. Why should you plan for data management and what is the typical content of a DMP? And when should you submit it?

**Licence:** [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.en)

**Transcript:**<!-- style="color: black; font-size: 20px;" -->

A data management plan or DMP is a document that outlines how research data will be handled during and after a research project. Creating a DMP is considered good practice for any research project that will use or generate data. Decisions made early on affect what you can do later, so good and timely planning can save you a lot of time and problems in the longer run. It also helps you consider the necessary resources and costs for data management - so you can budget for these and even include them in your grant applications. Planning can also help you to increase the FAIRness of your data and to make data FAIR by design. Data management plans are increasingly required by research institutions and funding agencies. These stakeholders recognize the intrinsic value of data and intend to increase scientific integrity and transparency and the accessibility and reuse of data collected by publicly funded research.

So what should be included in a data management plan?

If you are writing a DMP for your institution or funder it is important to check if a specific template is available or even required. Although DMP templates might slightly vary from organization to organization they usually cover the following topics: a summary or description of the data. You will need to indicate whether you will generate new data or use existing data sets and provide some basic characteristics about them - such as their origin, their type, their format and estimated size.

Metadata and documentation: what information will be provided to make data understandable and findable? And will this be provided following agreed standards?

Other DMP questions will deal with data storage and security: where will the data be stored? And how will you ensure that data is protected against risks? For example data loss due to human errors, computer failures or malicious attacks. And how to make sure that it cannot be accessed, deleted or modified by unauthorized persons? What about preservation? What data will be preserved after the end of the project? For how long and where?

Sharing and Reuse: what data can and will be shared? With whom and under which access and reuse conditions or licenses? Where and when will data be made available?

Another content block involves the possible legal or ethical issues related to your project's data. For example if you work with personal or otherwise confidential data, or any other situation where ethical approval is needed. Or if you work with third party data or you are planning to seek patent protection for your research results. These are all issues that will affect how you should collect, store and process your data and whether you can share them or not and under which conditions.

Responsibility should also be addressed: who bears the overall responsibility for implementing and regularly updating the dmp? Who is responsible for each of the different data management activities including documenting, storage and backups, preserving and sharing data?

And finally what about costs and resources? Are there any costs related to the implementation of the dmp? Will you need additional resources to cover these costs?

So that's for the content of a DMP but when are you supposed to submit a DMP? Well, it depends on the specific requirements of your institution or research funder. Usually, the life cycle of a data management plan looks like this: the proposal stage: this is where the various requirements diverge most. Your institution or funder might not have any specific requirements with regards to data management. Another possibility is that the proposal needs to address some RDM questions or include a light version of a DMP. In other cases, a preliminary but full version of the DMP might be required. When your project is approved. A first version of the DMP will usually be required shortly after - often no later than six months after the start date - but things can change over the course of the project. Or maybe certain things were not known at the beginning - that is why you are supposed to keep your DMP up to date throughout the course of the project. In some cases updated versions might be a deliverable with a specific deadline. At the end of the project it is likely that a final version of the DMP is requested - this should reflect the final decisions and approaches taken. For some funders the final DMP might be part of the project's final evaluation.

As we've mentioned, many institutions or research funders will provide a DMP template with a series of RDM related questions. However, there is a range of tools that can help you with the process of creating a data management plan. These tools will incorporate these templates. They will also provide you with some tips as you go along and allow you to export your final DMP in a format ready for submission. So before you start - check whether your institution provides a DMP tool. For example researchers from Ghent university and other belgian institutions can use dmponline.be. In our website you can find more information about data management plans and a video tutorial about dmponline.be. Why don't you have a look?

**Quiz**<!-- style="color: black; font-size: 20px;" -->

Why should you write a DMP?

      [( )] because it is a new requirement of the Federal Ministry of Education, Science and Research (BMBWF)
      [(X)] primarily to increase my sienctific integrity and because my institution or funders may ask for it
      [( )] no, it generally does not make sense writing a DMP because it is just an additional administrative burden

What topics should be included in a DMP?

      [(X)] how you will deal with storage and sharing of your research data
      [( )] a detailed cost listing of salaries and consumables
      [( )] administrative information of your former publications

When should you start writing a DMP?

      [( )] when the project is finished and almost published
      [(X)] best before the project starts because then you can properly plan the handling of your research data throughout the whole project lifecycle
      [( )] funders normally ask for it after publication of the research results

**Further information**<!-- style="color: black; font-size: 20px;" -->

* **Checklist for a Data Management Plan provided by DCC (Digital Curation Centre)**

  The checklist provides guidance and questions to consider when creating a DMP

  https://www.dcc.ac.uk/sites/default/files/documents/resource/DMP/DMP_Checklist_2013.pdf
* **Checklist for a Data Management Plan provided by SND (Swedish National Data Service)**

  This checklist guides you with questions trough the DMP core topics

  https://snd.gu.se/sites/default/files/page/Checklist%20Data%20Management%20Plan_2017-10-16.pdf
* **Data Management Planning Themes provided by DCC & UC3**

  This is a consolidated set of data management planning themes & guidance

  https://github.com/DMPRoadmap/roadmap-docs/blob/master/DMP-themes-Jan2017.pdf
* **Data management general guidance provided by DMPTool**

  This guide provides background information and help on all DMP core topics

  https://dmptool.org/general_guidance
* **DMPonline Tool for creating a DMP provided by DCC**

  DMPonline helps you to create, review, and share data management plans that meet institutional and funder requirements. It is provided by the Digital Curation Centre (DCC).

  https://dmponline.dcc.ac.uk/
* **RDMO Tool for creating a DMP (Research Data Management Organizer)**

  The Research Data Management Organiser (RDMO) enables institutions as well as researchers to plan and carry out their management of research data. RDMO can assemble all relevant planning information and data management tasks across the whole life cycle of the research data.

  https://rdmorganiser.github.io/
* **Data Steward Wizard**

  The Data Stewardship Wizard will effortlessly guide you through the creation of your data management plan by e.g. giving you hints about good data management practice, checking the FAIRness of your plan, or asking and following only questions relevant to your project

  https://ds-wizard.org/
* **Practical Guide to the International Alignment of Research Data Management – Extended Edition**

  Originally released in 2019, and following its successful uptake by many organisations, the extended edition features a brand-new rubric to facilitate the evaluation of a data management plan (DMP). The guide also presents core requirements for DMPs, criteria for the selection of trustworthy repositories, and guidance for researchers to comply with organisational requirements.

  https://www.scienceeurope.org/media/4brkxxe5/se_rdm_practical_guide_extended_final.pdf
* **FAIR Data Austria Webinar “Austrian Science Fund (FWF) Research Data Management”**

  have a look at the slides (https://phaidra.univie.ac.at/detail/o:1206158#?page=1&pagesize=10&fq=resourcetype_text&collection=o:1168881) and/or video (https://phaidra.univie.ac.at/detail/o:1202593#?page=1&pagesize=10&fq=resourcetype_video&collection=o:1168881, FWF DMP see minutes 36:18-55:00) from the Webinar “Austrian Science Fund (FWF) Research Data Management” to inform about DMPs in general and FWF requirements in particular. The Webinar is part of the Webinar Series “Research Data Management in Austria” (https://phaidra.univie.ac.at/o:1188972) aimed at researchers and/or research support staff and serves to promote networking and exchange on the topic of research data management – like writing a data management plan and related topics

**Citation**<!-- style="color: black; font-size: 20px;" -->

FAIR Data Austria (2021). “Data Management Plan (DMP)“. In: Research Data Management Open Educational Resources Collection. (https://fair-office.at/index.php/dmp/?lang=en).

License: [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/) unless otherwise stated.




## FAIR Data vs. Open data




**FAIR Data**

[FAIR](#FAIR-Principles) stands for Findable, Accessible, Interoperable and Reusable and refers to sustainable research data management. The main goal of the FAIR data principles is to optimise the preparation of research data, making it findable, accessible, interoperable and reusable.

**Open Data – Free primary research data**

The free availability and usability of data on the web is often referred to as open data. It is data that has been made available without any restriction for free use, further dissemination and free reuse. Various licences can be used to identify data as open data.

**The FAIR Principles and Open Data**

FAIR data is not the same as open data. For example, it is not always possible to grant free access to data for economic and legal reasons. Restrictions on access are compatible with FAIR principles, as long as the conditions and ways of access are evident.

!?[youtube](https://youtu.be/5OeCrQE3HhE)

**Duration:** 2:09 min

**Content:** This video explains the difference between data that complies with the FAIR data principles and open data, which is freely accessible to anyone.

**Licence:** [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.en)

**Transcript:**<!-- style="color: black; font-size: 20px;" -->

No matter what kind of research you do or where you are in your career, sooner or later you will come across the FAIR principles for research data. Applying the [FAIR principles](## FAIR Principles) means to make your research data findable, accessible, interoperable and reusable. Findable means that others can discover your data. Accessible means that your data can be made available to others. Interoperable means that your data can be integrated with other data or can be easily used by machines. Reusable means that your data can be used for new research. These four principles should be applied throughout the entire data life cycle and they are closely interconnected.

Please note applying the FAIR principles to your research workflows does not necessarily mean that you share your data openly. FAIR data is not the same as open data. Open data is data that can be freely used, shared and built on by anyone anywhere and for any purpose, while the FAIR principles provide a set of best practices for sharing data respecting any ethical, legal or contractual restrictions. If your data contains personal information or is subject to copyrights or intellectual property rights you must comply with regulations and protect your data from unauthorized access. But even if the data itself cannot be shared openly, you should create and publish a description of your data so that researchers with a relevant purpose can request permission to reuse the data.

This module introduces you to best practices for making your data FAIR. Following these best practices will help you to produce high quality data that can result in maximizing your research output and impact and enhancing your recognition as a researcher.

**Quiz**<!-- style="color: black; font-size: 20px;" -->

What does the acronym FAIR stand for?

    [(X)] Findable, accessible, interoperable, reusable
    [( )] Factorial, analysable, informative, recognizable
    [( )] Fair, accurate, inclusive, respectful

Which statement about Open Data is correct?

    [(X)] Open Data means information that is freely accessible.
    [( )] With Open Data, only data that is related to a scientific interpretation can be considered.
    [( )] With Open Data, the availability and usability of data on the web is limited.

FAIR data is always open data

    [( )] True
    [(X)] False

**Further information**<!-- style="color: black; font-size: 20px;" -->

* **FAIR self-assessment tool:** With this free online tool you can evaluate the “FAIRness” of a data set by answering questions about the individual aspects of FAIR.

  https://ardc.edu.au/resources/working-with-data/fair-data/fair-self-assessment-tool/
* **How to Make Your Data FAIR:** You can find more tips on making your data FAIR on the OpenAIRE ([Link OpenAIRE](https://www.openaire.eu/)) website.

  https://www.openaire.eu/how-to-make-your-data-fair

**Citation**<!-- style="color: black; font-size: 20px;" -->

FAIR Data Austria (2021). “FAIR data vs. Open Data”. In: Research Data Management Open Educational Resources Collection.  (https://fair-office.at/index.php/fair-data-vs-open-data/?lang=en).

**License:** [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/) unless otherwise stated



## FAIR Principles



In 2016, FORCE11 – a group of researchers as well as employees of libraries, archives, publishers and funders – established principles for the handling of research data. The so-called FAIR principles comprise four goals: the findability, accessibility, interoperability and re-usability of data. With the achievement of these goals, the sustainable re-usability of research data is meant to be guaranteed.

Biernacka, Katarzyna, Bierwirth, Maik, Buchholz, Petra, Dolzycka, Dominika, Helbig, Kerstin, Neumann, Janna, … Wuttke, Ulrike. (2020). Train-the-Trainer Concept on Research Data Management (Version 3.0). Zenodo. http://doi.org/10.5281/zenodo.4071471 p. 36, Creative Commons Attribution 4.0 International

!?[youtube](https://youtu.be/2uZxFu9SFi8)

**Duration:** 4:45 min

**Content:** In this video we take a look at FAIR data and the meaning of the individual FAIR principles (findable, accessible, interoperable and reusable).
It also covers how (trusted) data repositories are a key infrastructure that enables FAIR data.

**Licence:** [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.en) For documentation; source of License: [Catalogue – D4Science Infrastructure Gateway](https://eosc-pillar.d4science.org/catalogue-eoscpillar?path=/dataset/knowledge_clip_-_fair_data_principles)

**Transcript:**<!-- style="color: black; font-size: 20px;" -->

**What are the FAIR principles and what is FAIR data**? FAIR are a set of guiding principles that** enable and increase the reuse of data by humans and machines**. FAIR is an acronym that stands for **Findable, Accessible, Interoperable and Reusable**. The FAIR principles originated in the life sciences, but can be applied to all disciplines. They are increasingly gaining traction and becoming **a requirement by many research funders among others**. Let's have a look at what each FAIR principle means.

**FINDABLE:** To** enable its discovery, data should be described with rich metadata, and it should be assigned a persistent identifier, such as a digital object identifier or DOI**. These metadata should be available online in a searchable resource such as a data catalog or repository.

**ACCESSIBLE:** Metadata and/or the data themselves should be retrievable via their persistent identifier using a standard communication protocol, such as HTTP or HTTPS. This means that following the persistent identifier should take you to the metadata or data. However, keep in mind that **accessible** **does not mean that data must be open** in the sense that there are no access restrictions. It rather means that if data **has access conditions, these are clear to both humans and machines**. Therefore the protocol for accessing the data should allow for an authentication and authorization procedure where necessary. In addition, metadata should be accessible even if the data themselves are no longer available.  

**INTEROPERABLE:** Whenever possible, metadata and data should use **recognized standards**. By using formats, terms or vocabularies, that a community has agreed upon, we make sure our data is understandable by others but we also make possible for data **to be exchanged and combined across computer systems**. Interoperability also involves **providing context by including references to other relevant metadata and data**. For example by linking to another data set on which your data set is built.

**REUSABLE:** Data should **not only be available, but also effectively reusable.** To achieve this, data should be abundantly **described and documented in accordance with community standards**. Metadata and documentation should be able to answer the W-questions, to help **others understand what we call the provenance of the data**. In other words, where did data come from and what happened to them along the way. All of this is needed when we want others to understand the context of the data and judge how relevant and useful they are. It increases trust and the likelihood of reuse to make data reusable. We also need to let others know what kinds of reuse are permitted, by including a clear data usage license.

Given the multiple aspects of FAIR, data is not either FAIR or UNFAIR. FAIR is a spectrum, in other words data can be **FAIR to a greater or lesser extent**. So, how can you make your data FAIR? Unfortunately there is **not a one-size-fits-all**, but note that much of the work for making your research data FAIR can be addressed by depositing your data in a trusted data repository. By choosing an appropriate **trusted and preferably domain-specific repository** you can score many points in the FAIR game. When you upload your data to a repository you will typically **need to provide metadata by filling a form**. The elements of the form comply with a specific metadata standard. Your metadata will then become **machine-actionable and searchable in an online resource**. The repository should also generate a **persistent identifier for your data**. It will also provide the possibility to include references to other data or metadata; for example to link to related data sets or your ORCiD. In addition, trusted repositories will have authentication and authorization procedures in place to make sure that appropriate access conditions for the data are respected or enforced. And repositories also allow you to choose from machine-readable **licenses** enhancing the reusability of your data. **Domain specific repositories tend to make use of discipline standards and controlled vocabularies**, increasing the interoperability of your data.

**Data repositories are indeed a key infrastructure enabling FAIR data**. However, they won't do all the work for you. After all, you are the one that knows the data best. So you are still **responsible to provide rich metadata and documentation to make the data understandable**. Besides, if a discipline repository requires the data to be in a certain standard format and to use controlled vocabularies, the standardization process is still your job to do. Therefore, **the sooner data is being collected and managed in a FAIR way, the easier it will be to keep the data FAIR in the end.** This is sometimes referred to as making data FAIR by design. That is why planning for data management even **before you start collecting data is essential**. So are you ready to make your data FAIR?

**Quiz**<!-- style="color: black; font-size: 20px;" -->

Which of the following scenarios comply with the FAIR criteria?

    [[ ]] Within a project, extensive Excel tables with different data have been created. For the purpose of long-term archiving, these tables are published as PDF files in a research data repository.
    [[X]] The data are provided with an individually specified license.
    [[X]] After completion of the project, the data is published in a repository with a free and open protocol, e.g. http.
    [[X]] If different versions of a data set exist, links are provided to the other versions.

FAIR is an acronym that stands for...

    [(X)] Findable, Accessible, Interoperable and Reusable
    [( )] Facebook Artificial Intelligence Research
    [( )]Fair, Accurate, Inclusive and Respectful Education

In which disciplines can the FAIR data principles be applied?

    [(X)]All disciplines
    [( )] Humanities
    [( )] Natural sciences

Accessible means…

    [[ ]] the date must be open.
    [[X]] the data does not necessarily have to be open.
    [[X]] the data has access conditions and these are clear to both humans and machines.
    [[ ]] the data is open for access, but not for reuse.

How do we make sure our data is understandable?

    [(X)] By using formats, terms or vocabularies, that a community has agreed upon.
    [( )] By adding a special glossary that explains our data.
    [( )] Our data should not be understandable by potential reusers.

Reusable means…

    [(X)] that the data has clear usage licenses and is usable by both people and machines.
    [( )] that all data is usable.
    [( )] that the data has clear usage licenses to be used by people.


**Further information**<!-- style="color: black; font-size: 20px;" -->

* **Comment in Nature regarding FAIR Principles**

[Wilkinson, M. D. et al. (2016). The FAIR Guiding Principles for scientific data management and stewardship. Sci. Data 3:160018](http://doi.org/10.1038/sdata.2016.18)

* **FAIR-Principles and the European Commission**

[European Commission. Action Plan for FAIR data recommendations](https://ec.europa.eu/info/sites/default/files/turning_fair_into_reality_1.pdf)

[The EC expert group on FAIR data](http://ec.europa.eu/transparency/regexpert/index.cfm?do=groupDetail.groupDetail&groupID=3464&NewSearch=1&NewSearch=1)

[EC/H2020 – Guidelines on FAIR Data Management in Horizon 2020](http://ec.europa.eu/research/participants/data/ref/h2020/grants_manual/hi/oa_pilot/h2020-hi-oa-data-mgt_en.pdf)

* **GO FAIR Initiative**

GO FAIR is a bottom-up, stakeholder-driven and self-governed initiative that aims to implement the [FAIR data principles](https://www.go-fair.org/fair-principles/), making data Findable, Accessible, Interoperable and Reusable (FAIR). It offers an open and inclusive ecosystem for individuals, institutions and organisations working together through [Implementation Networks](https://www.go-fair.org/implementation-networks/) (INs). The INs are active in three activity pillars: [GO CHANGE](https://www.go-fair.org/fields-of-action/go-change/), [GO TRAIN](https://www.go-fair.org/fields-of-action/go-train/) and [GO BUILD](https://www.go-fair.org/fields-of-action/go-build/).

https://www.go-fair.org/fair-principles/

* **The FAIR Office Austria, which is part of the global GO FAIR initiative, networks researchers and service institutions to implement the FAIR principles.**

[FAIR Office Austria](https://fair-office.at/?lang=en)

* **Training material for “FAIR” in the train-the-trainer program for Research Data Management**

Biernacka, Katarzyna, Bierwirth, Maik, Buchholz, Petra, Dolzycka, Dominika, Helbig, Kerstin, Neumann, Janna, … Wuttke, Ulrike. (2020). Train-the-Trainer Concept on Research Data Management (Version 3.0). Zenodo. http://doi.org/10.5281/zenodo.4071471 (p. 38)

* **OPENAIRE**

A network of Open Access repositories, archives and journals that support Open Access policies. The OpenAIRE Consortium is a [Horizon 2020](https://en.wikipedia.org/wiki/Framework_Programmes_for_Research_and_Technological_Development#Horizon_2020) (FP8) project, aimed to support the implementation of the [EC](https://en.wikipedia.org/wiki/European_Council) and [ERC Open Access](https://en.wikipedia.org/wiki/Open_Access) policies.

https://www.openaire.eu/how-to-make-your-data-fair

* **FAIR-Principles and the Committee on Data for Science and Technology (Codata)**

The [Committee on Data for Science and Technology](https://codata.org/) (CODATA) is a Paris-based organization with the aim of improving the quality, reliability and accessibility of interesting data from all fields of science and technology.

[Hodson, S. (2018). Making FAIR data a reality… and the challenges of interoperability and reusability. Open Science Conference 2018.](https://www.open-science-conference.eu/wp-content/uploads/2018/03/OSC2018_Hodson.pdf)


**Citation**<!-- style="color: black; font-size: 20px;" -->

FAIR Data Austria (2021). “FAIR data vs. Open Data”. In: Research Data Management Open Educational Resources Collection.  (https://fair-office.at/index.php/fair-prinzipien/?lang=en).

**License:** [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/) unless otherwise stated



## Research Data Management (RDM)



Research data management (RDM) includes all activities with digital research data that ensure their permanent availability and comprehensibility. It refers to measures regarding proper data handling throughout the whole research data lifecyle – from planninig a research project, data collection and documentation, to storage, sharing and publication of research data. Good RDM practices should contribute to reusable research data that enables new, innovative research based on already existing information and should support traceability and verification of previous research results. When it comes to RDM, a so called [Data Management Plan (DMP)](#Data-Management-Plan-%28DMP%29) is the method of choice. A DMP is a structured document that describes how research data will be handled during and after the project end.

!?[youtube](https://youtu.be/bbsLmy3Njv4)

**Duration:** 3:50 min

**Content:** The video gives a short introduction to the concept of “research data management”. Ghent University Data Stewards (2020). Knowledge clip: What is Research Data Management (RDM)?

**Licence:** [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.en) For documentation; source of License: [Catalogue – D4Science Infrastructure Gateway](https://eosc-pillar.d4science.org/catalogue-eoscpillar?path=/dataset/knowledge_clip_-_fair_data_principles)

**Transcript:**<!-- style="color: black; font-size: 20px;" -->

What is research data management? Research data management or RDM is a broad term encompassing **all practices and actions to ensure that research data are secure, sustainable, easy to find, understand and reuse**. But what does that actually mean? Let's dissect research data management. It consists of two concepts: research data and management.

So what are **research data**? It is hard to come up with one definition for research data, because it is highly domain and context specific. Therefore we refer to  **research data as any information collected or generated for the purpose of analysis, in order to generate or validate scientific claims**. There is a huge  **variety of data types**. Research data can be classified in different ways, for example based on their content, numerical, textual, multimedia etc. Based on their format, spreadsheets, databases, images, maps, audio files, or based on the collection mode such as experimental data, observational simulation, or derived, or compiled from other sources. Or for example its digital or non digital nature, or its primary or secondary character. Has the data been generated by the researchers for a specific purpose, or was it originally created by someone else for other purpose? Finally, is the data raw or processed? Keep in mind that besides the research data itself, RDM also extends to managing documentation needed to make those data understandable.

Now what is the  **management of research data**?  **Management refers to activities or actions, such as planning, collecting and organizing data, documenting and describing, storing and backing up and preserving, sharing, and controlling access to research data.** These actions take place at different phases of what we call the  **research data lifecycle**. So our DM is about taking proper care of data not only during but also after research, so that  **data is preserved and can be used in the longer term**. Research data are not just a byproduct of scientific research, nor a simple means to article publication.  **On the contrary, research data should be cared for as first-class research objects and RDM is about exactly that.** Two concepts related to research data management are FAIR and Open. [FAIR](https://fair-office.at/?page_id=5870&amp;lang=en) **stands for Findable, Accessible, Interoperable, and Reusable.** With good RDM practices, we aim to make data FAIR and as open as possible, but as closed as necessary. Implementing good RDM practices can initially take  **some effort in time, but it also yields significant benefits for yourself, the research community, and society at large**. No wonder RDM is increasingly being considered an essential  **part of good research practice**. Good reasons for properly managing and sharing research data range from more selfish, pragmatic reasons, to more altruistic reasons. Think for instance of minimizing the risk of losing valuable data, or increasing your research efficiency and the impact and visibility of your research, but also accelerating scientific discovery and living up to the principle, that publicly funded research is a public good. Do you want to know more? Why not have a look at our webpages (https://www.ugent.be/en/research/datamanagement)?

**Quiz**<!-- style="color: black; font-size: 20px;" -->

What are research data?

    [[X]] Interviews
    [[X]] Photos
    [[X]] Simulations
    [[X]] Software

What is research data?

    [( )] Research data is any information of metadata and primary research data.
    [(X)] Research data is any information collected or generated for the purpose of analysis, in order to generate or validate scientific claims.
    [( )] Research data is any data, that is generated during a scientific work process.

Which activities are included in research data management?

    [[ ]] Application for funding
    [[X]] Writing a DMP
    [[X]] Collecting and organizing research data
    [[X]] Documenting and describing research data
    [[X]] Storing, backing up and preserving research data
    [[X]] Sharing and controlling access to research data

What is the management of research data?

    [( )] It refers to organization of metadata standards
    [(X)] It refers to activities or actions, such as planning, collecting and organizing research data.
    [( )] It divides the personal data from the study data.

Who profits from research data management?

    [[X]] The team members who are involved in the project
    [[X]] The research community
    [[X]] The society
    [[ ]] Someone who loves bureaucracy

**Further information**<!-- style="color: black; font-size: 20px;" -->


* **Website [forschungsdaten.info](http://forschungsdaten.info/)**

Comprehensive information about research data management on the website forschungsdaten.info

https://www.forschungsdaten.info/praxis-kompakt/english-pages/

* **Event Series “Research Data Management in Auastria”**

The event series “Research Data Management in Austria” is aimed at researchers and / or people involved in research support and serves to promote networking and exchange on the topic of research data management, writing a data management plan and similar related topics. Below you find domain specific material (slides and videos) regarding Research Data Management:

* Hönegger, Lisa (9th March 2021). Research Data Management in the Social Sciences: RDM basics, challenges and support. [Presentation. Webinar for the event Research Data Management in Social Sciences]. Handle: [11353/10.1168878](https://hdl.handle.net/11353/10.1168878)
* Medical University of Graz und BioTechMed-Graz (8th June 2021). Research Data Management (RDM) in the Life Sciences: From Writing DMPs to RDM Practices and RDM Support. [Slides. Research Data Management in the Life Sciences]. Handle: [11353/10.1206156](https://hdl.handle.net/11353/10.1206156)
* Medical University of Graz und BioTechMed-Graz (8th June 2021). Research Data Management (RDM) in the Life Sciences: From Writing DMPs to RDM Practices and RDM Support. [Video. Research Data Management in the Life Sciences]. Handle: [11353/10.1202593](https://hdl.handle.net/11353/10.1202593)

* Train-the-Trainer Concept on Research Data Management provided by FDMentor

The train-the-trainer program on research data management (RDM) comprises the aspects of research data management as well as didactic units on learning concepts, workshop design, and a range of didactic methods

Biernacka, Katarzyna, Bierwirth, Maik, Buchholz, Petra, Dolzycka, Dominika, Helbig, Kerstin, Neumann, Janna, … Wuttke, Ulrike. (2020). Train-the-Trainer Concept on Research Data Management (Version 3.0). Zenodo. http://doi.org/10.5281/zenodo.4071471 (from p. 36 on)

* **Research Data Management and Science Europe**

https://scienceeurope.org/our-priorities/research-data/research-data-management/

* **Practical Guide to the International Alignment of Research Data Management – Extended Edition provided by Science Europe**

This resource offers targeted guidance for organisations, scientific communities, as well as individual researchers, to organise research data and preserve it appropriately. Originally released in 2019, and following its successful uptake by many organisations, the extended edition features a brand-new rubric to facilitate the evaluation of a data management plan (DMP). The guide also presents core requirements for DMPs, criteria for the selection of trustworthy repositories, and guidance for researchers to comply with organisational requirements.

https://scienceeurope.org/our-resources/practical-guide-to-the-international-alignment-of-research-data-management/

**Citation**<!-- style="color: black; font-size: 20px;" -->

FAIR Data Austria (2021). “FAIR data vs. Open Data”. In: Research Data Management Open Educational Resources Collection.  (https://fair-office.at/index.php/fdm/?lang=en).

**License:** [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/) unless otherwise stated



## Metadata



~~Data documentation~~

In order to make research data more findable and comprehensible, documentation of data is essential. It considerably facilitates the further use of the data and enables reproducibility. Well-documented data will be used and cited more often, which will increase the reputation of the creator. Documentation is also important with regard to the subsequent usability and traceability of the data for your own work. Over time, details might be forgotten, so it is recommended to document the data while working on it. read less

Basic contents of a documentation include:

* description of the research project
* project goals
* hypotheses
* detailed information on data collection (methods, units, time periods, locations, technology used)
* measures for data cleansing
* structure of data and their relationships to each other
* explanation of variables, labels and codes
* differences between versions
* information on access and terms of use

~~What is metadata?~~

Metadata refers to structured data that contains information on other data – “data about data”. They are stored either independently of or in combination with the data they describe. There is a distinction between content-related and technical metadata. They form a specific subset of the documentation data and serve primarily to make the data findable, including in library reference systems. In order to make them machine-readable, for example in Semantic Web applications, they are often stored in XML format.

~~Metadata standards~~

Standardisation of metadata vocabulary is necessary to improve findability of the data and to provide interoperability. The linking of the metadata will ensure this. Furthermore, standards allow a uniform description of similar data sets in terms of content and structure.

Metadata standards contain a defined selection of information which is necessary to find and identify these data. This does not necessarily guarantee a reusability of the data (compare section on documentation). Among the most common bibliographic interdisciplinary metadata standards are Dublin Core, DataCite Metadata Schema, and MARC21.

~~Discipline-specific metadata standards~~

Since each scientific community has its own requirements, different discipline-specific metadata standards are also being developed. For example, in the social and economic sciences the Data Documentation Initiative (DDI) standard is frequently used, while in the natural sciences the ICAT scheme or the Crystallographic Information Framework are used.

An overview on discipline-specific metadata standards is available, for example, on the pages of the British Digital Curation Centre49 and in an overview of the Research Data Alliance.

(Biernacka, K., Bierwirth, M., Buchholz, P., Dolzycka, D., Helbig, K., Neumann, J., Odebrecht, C., Wiljes, C. and Wuttke, U. (2020). “Train-the-Trainer Concept on Research Data Management” Version 3.0. Berlin, DOI: https://doi.org/10.5281/zenodo.4071471, Creative Commons Attribution 4.0 International)

!?[youtube](https://youtu.be/1eCMRhbi60U)

**Duration:** 14:30 min

**Content:** Research Data and their Metadata” is an educational video on research data management. The video briefly explains the concept of metadata and where in the research data lifecycle they become important.

(Schmitz, D., Hausen, D., Trautwein-Bruns, U. (2018). “Research data and their metadata” RWTH Aachen University, DOI: 10.18154/RWTH-2019-10060)

**Licence:** [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.en)

**Transcript:**<!-- style="color: black; font-size: 20px;" -->



Welcome to our series on research data management! Today's topics are **research data and their metadata**. So, we are talking about, mainly, the metadata, so what metadata means and what metadata occur, typically, within research data context. We again refer to our fake science example on squirrel research. So within this project Luise Leader has built a theoretical model to look at the population dynamics of squirrels, and she has compared her theoretical ideas with concrete data gatherings from Frank Forscher in Germany and Rachel Research in Great Britain. When she looks back at this project, she remembers that it, of course, was successful but, on the other hand, that there have been quite some data management issues. And the main point in regard to this data management was that she didn't prescribe the other researchers how to do their data management, how to do their data gathering. And that was really something that, well, caused some problems.

Unfortunately Frank and Rachel gathered the data quite differently. Frank Forscher built on the many projects that he has done before. So, for example, he builds up an Excel file for each year where the different sheets represent the different federal states of Germany and you have a row for each month and you have columns then for the number of brown squirrels and the number of black squirrels. So, that was, in a way, his approach. Now Rachel. So, she travelled around a lot, moving from one location to the others, talking to the rangers, and from this it became obvious that it might make sense to organize her data on files that are collected for each month. And where you have the rows representing the different countries like Scotland, Wales and England, where she doesn't use the countries, but some country code that has been defined in a separate file. And then she used the notation stating that 'b' was black and 'r' for red-brown. So if you look at these data, you obviously see that they are somehow incompatible.

So, it really took quite some time for Luise to find out and understand the different approaches and to also arrive at a situation where she could merge the two observations into the same format in order to compare it to her theoretical model. So, for Luise it has become clear that **it makes sense to put some more effort into the data management, into the planning and deciding what and how data should be gathered in the future**. So, this is kind of a data documentation in the first place and we will now look at some recommendation that you could follow as well and when you try to set up scenarios or data management collection scenarios. One idea is to introduce an identifier for each observation that you make. Of course, this is typically something that is auto-generated by the measurement point that you use. But you must think about whether you want to have some things like that and what it can be used for and how it can be used.

The next aspect is that you should, for example, if you state the date when some observation has taken place, that you should agree on the format that you use here. For example, you could agree on the **format ISO 8601, specific stating how exactly the date together with the time is represented** here. If you do that, it makes it much easier to aggregate the data because you can merge, easily merge the data that has been collected from different places. And you, for example, can aggregate it on a monthly level, or you can even refer to a particular other information like wheather information, for example. The next point is that Luise was interested in distinguishing the number of red-brown versus black squirrels. So, unfortunately, Rachel and Frank have chosen different ways to represent that. So, this is really something where you should impose some vocabulary, some controlled vocabulary. Of course, if you have a standard or something that is agreed upon in your community. If you don't have that, then simply ask your people to follow one approach, for example, saying, well, we use 'b' for black and 'r' for red-brown and not 'b' for brown which then leads to misunderstandings.

Another aspect is something that turns up also in the persistent identifier video. Because if you have your observation points, it might make sense to treat them as data on their own. So, also giving IDs to them and then recording some particular information about them. For example, your exact latitude longitude information, the geographical location of this observation point, maybe also the hardware, the camera that is working within this observation point in order to detect the color of a squirrel. So, this is some kind of the data that the people should agree on, but that's not enough. So, they must also talk about - or ensure - that they have the same understanding of the data. So, **this is where metadata comes into play**. Of course, it's, in the first place, it's something at least like the column heading of these different columns. So, having ID, having something like date, location, or color. But typically this is even far too short. So, you must have some place where you have some additional information, where you exactly explain how you generate the IDs. For example, whether these are integer numbers or something else, how you record your date, ISO format or not, and also the locations you must agree on. If you register your observation points with some central registry, then you must agree on this procedure and ensure that all the locations are really registered. And the similar thing for the coloring. And that you should use, indeed, a vocabulary that is defined at least in the community or if you don't have that, then decide it for your project how you want to - the different things to be named here. And when Luise looks back at this, she also sees that, well, these observation points that she has used via Rachel and Frank within this project, they also gather the data of the size of the squirrel.

So, while she was not interested in this data, it would of course make sense to record this data as well. Because maybe some other would be interested in exactly this data. And that's exactly what we create here by some follow-up project by Remy Reuse, who wants to look at the evolution of squirrels in entire Europe and is asked to build on the work of Luise and, indeed, he's interested, for example, in the size of the squirrels and that's something that, if Luise has not taken care that this information is preserved as well, can be impossible to build on that.

This has given you some idea of metadata in a very concrete processing but also in a reusing scenario. So, let's look again at the entire research data lifecycle. During planning, of course, you focus on the key elements that your research is about and what data and metadata you want to select here. So, the data gathering is relevant but also maybe your theoretical model, how it is planned, how it is described. Things like that are something that you already have available at the planning level. Also, responsibilities is the kind of a metadata information that Frank Forscher is responsible for Germany and Rachel Research for Great Britain. It's some kind of a metadata that should be available and documented. The next is the point on production, on data collection and -gathering. That's what we looked at in detail within this video. So, typically you have here something like established vocabularies and any additional context information like, for example, the table of observation point locations with any additional detail of the observation measurements. **So, this is really something where you can specify your approach and define what information needs to be recorded.**

And this is typically done in order to support the analysis phase where you, for example, want to put the things together as we have seen here with Rachel and Frank. And any approach regarding the selection and validation is also some kind of a metadata. So, if you want to only look at the data in either National Park, you must somehow specify how you want to make that selection. You can say, okay, I take the following five observation points or I specify the geographical region and derive which of the observation points reside within this geographical region by comparing latitude and longitude information. You should note down which approach you used in order to look later at your data and maybe understand why some piece of information is wrong because maybe some data is wrong or something like that. So this is also something that supports provenance. Any aggregation approach is also something that is relevant. For example, Luise was only interested in a number of squirrels per month, right? So, we have now seen that within the data model that we looked at today we have an ISO 8601 data format. So, it's rather clear how you arrive at monthly numbers then. And if you record all this kind of information, and how you treat the approaches, and how you're doing that, you also add to your data quality because you make it possible to understand how the data was derived from each other. If you arrive at the level of storage, there are some obvious metadata information, for example, the file format. **If you don't know the file format of some file you have really problems in open it and understanding it.** But also, for example, the location at the date of the preservation is relevant. Because it helps you to find out whether it makes sense to look at some particular data or if it doesn't make sense because the point that you are interested in has occurred later, for example. And, of course, any additional tooling, for example, that you need in order to correctly interpret the data is something that should be specified. Because otherwise you can't use the data that you have produced there.

Regarding access and reuse, for example, if you publish your data the **[DOI](#Persistent-Identifier-%28PID%29)** is certainly something that is important metadata information. Also the repository where your data is published. Or the provenance information, for example, who put the data in the repository, where did it come from, how was it derived. All these things are again relevant here. Another point that is very important - and we will also have a particular video on this - that if you have publications and you have data, it makes sense to note down how they relate. So, what data went into which publications and what publications build on what data? If you have that information easily available then you can easily answer, for example, requests on earlier data that typically arrive because somebody has read your publication. And, of course, the **license** is also an important metadata information that you produce when you want to publish, for example. Yet, as you can see, there are a lot of metadata occurring throughout the research data lifecycle. And the question is now, of course, how to cope with that, what to do. One recommended good practice is that you make use of a data management plan.

That is something that we detail out in different videos on a generic idea of a [Data Management Plan (DMP)](#Data-Management-Plan-%28DMP%29), as well as the particular contents. The core idea that you take here is, that it's kind of a documentation of your data management. But not only your data management, also your metadata management. And this concerns any phase of the entire research data lifecycle. And typically, a data management plan evolves over time. So, start simple and in the best case in the end you have an entire complete documentation of your data and metadata management within your project and can refer to that document for any question that somebody has, for example, if Remy wants to reuse the data of Luise for his new project. So, in our set up it has become clear that Luise is really thinking that it's a good idea to put more effort into the data management beforehand in order to have less problems within the project but also after the project has been ended. Because if you look at the metadata and store metadata, it helps you maintain your research data, it helps to merge them, for example, it helps to find your data again, for example, the different regions that you have looked at.

You also understand your research data, for example, looking at the controlled vocabulary you simply know, okay, 'r' is red-brown, 'b' is black. So, that's how everything is treated within this project. And there's typically, hopefully, one place where you can look up things like that. So, altogether it helps you use your research data but also if you want to hand it over to others, for example, if you publish it or if others ask for your data, then it's much easier for them to reuse your data. So, all the metadata management, even though it sounds a little bit abstract, is really something that provides you with some additional information, some context information that is needed in order to correctly interpret and use your data.

If you have any more questions on metadata or metadata management, just contact us via the service desk. Thank you!

**Quiz**<!-- style="color: black; font-size: 20px;" -->

What is metadata?

    [( )] Statements about the reviewer's data.
    [( )] A metaphysically based typology of data.
    [(X)] Independent data that contains structured information about other data or resources and their characteristics.

Why is metadata important?

    [(X)] Because they improve the reusability and accessibility of scientific results.
    [( )] Because they describe the researcher, making him/her uniquely identifiable.
    [( )] Because they evaluate a scientific publication.

What are metadata standards?

    [(X)] Generic Standards are, e.g., the Dublin Core Standard or Data Cite but there are also discipline-specific standards.
    [( )] There are no standards, every researcher has to develop his/her own “rule book”.
    [( )] The Dublin Core Standard and Data Cite are the only standards to be used by all scientists in all disciplines.

**Further information**<!-- style="color: black; font-size: 20px;" -->

**Metadata standards directory:**

A comprehensive list of metadata standards with short description and further links.

https://rd-alliance.github.io/metadata-directory/

**Metadata and describing data:**

A short description on the topic of metadata with examples and further links.

https://data.research.cornell.edu/content/writing-metadata

**Metadata Guide by Australian Research Data Commons (ARDC):**

This Guide is intended to provide a simple generic working-level view of the needs, issues, and processes around metadata collection and creation as it relates to research data.

https://ardc.edu.au/wp-content/uploads/2020/03/Metadata.pdf

**Citation**<!-- style="color: black; font-size: 20px;" -->

FAIR Data Austria (2021). “FAIR data vs. Open Data”. In: Research Data Management Open Educational Resources Collection.  (https://fair-office.at/index.php/metadaten/?lang=en).

**License:** [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/) unless otherwise stated


## Open Science

## Persistent Identifier (PID)

## Publication of data
